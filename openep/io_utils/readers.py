# OpenEP
# Copyright (c) 2021 OpenEP Collaborators
#
# This file is part of OpenEP.
#
# OpenEP is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# OpenEP is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program (LICENSE.txt).  If not, see <http://www.gnu.org/licenses/>

"""
Loading datasets --- :mod:`openep.io.readers`
=============================================

This module contains functions to load an OpenEP dataset.

Note
----

`openep-py` is currently only able to load:
    * data exported from the MATLAB implementation of OpenEP. Further, the `rfindex` data is not yet loaded.
    * data from an openCARP simulation


Example of loading a dataset
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Case data can be loaded as follows:

.. code:: python

    import openep
    from openep._datasets.openep_datasets import DATASET_2

    case = openep.load_openep_mat(DATASET_2)

This will load the dataset and store the information in a `Case` object.
See :class:`openep.data_structures.case.Case` for information on the attributes
and methods of `Case`.

.. autofunction:: load_openep_mat
.. autofunction:: load_opencarp

"""

import os
import re
import scipy.io

import numpy as np
import pyvista

from .matlab import _load_mat_v73, _load_mat_below_v73
from ..data_structures.surface import extract_surface_data, Fields
from ..data_structures.electric import extract_electric_data, Electric
from ..data_structures.ablation import extract_ablation_data, Ablation
from ..data_structures.vectors import extract_vector_data, Vectors
from ..data_structures.case import Case

__all__ = ["load_openep_mat", "_load_mat", "load_opencarp", "load_circle_cvi", "load_vtk", "load_igb"]


def _check_mat_version_73(filename):
    """Check if a MATLAB file is of version 7.3"""

    byte_stream, file_opened = scipy.io.matlab._mio._open_file(filename, appendmat=False)
    major_version, minor_version = scipy.io.matlab._miobase.get_matfile_version(byte_stream)

    return major_version == 2


def _load_mat(filename):
    """Load a MATLAB file."""

    if _check_mat_version_73(filename):
        data = _load_mat_v73(filename)
    else:
        data = _load_mat_below_v73(filename)

    # These are indices
    data['surface']['triRep']['Triangulation'] -= 1

    return data


def load_openep_mat(filename, name=None):
    """
    Load a Case object from a MATLAB file.

    Currently, cases can only be loaded from files created using the MATLAB
    implementation of OpenEP.

    Args:
        filename (str): path to MATLAB file to be loaded (including the .mat
            extension.)
        name (str): name to give this dataset. The default is `None`, in which case
            the filename is used at the name.

    Returns:
        case (Case): an OpenEP Case object that contains the surface, electric and
            ablation data.
    """
    data = _load_mat(filename)

    if name is None:
        name = os.path.basename(filename)

    points, indices, fields = extract_surface_data(data['surface'])
    electric = extract_electric_data(data['electric'])
    ablation = extract_ablation_data(data.get('rf'), data.get('rfindex'))
    vectors = extract_vector_data(data['surface'], indices)

    if 'notes' in data:
        notes = np.asarray([data['notes']])[:, np.newaxis] if isinstance(data['notes'], str) else np.asarray(data['notes']).reshape(-1, 1)
    else:
        notes = np.asarray([""], dtype=str)[:, np.newaxis]

    return Case(name, points, indices, fields, electric, ablation=ablation, notes=notes, vectors=vectors)


def load_opencarp(
    points,
    indices,
    fibres=None,
    name=None,
    scale_points=1,
):
    """
    Load data from an OpenCARP simulation.

    Args:
        points (str): Path to the openCARP points file.
        indices (str): Path to the openCARP element file. Currently, only triangular meshes are
            supported.
        fibres (str, optional): Path to the openCARP fibres file.
        name (str, optional): Name of the dataset. If None, the basename of the points file
            will be used as the name.
        scale_points (float, optional): Scale the point positions by this number. Useful to scaling
            the units to be in mm rather than micrometre.

    Returns:
        case (Case): an OpenEP Case object that contains the points, indices and fibres.

    Note
    ----
    All other attributes of the Case object will be set to None.

    """

    name = os.path.basename(points) if name is None else name

    # pts data
    points_data = np.loadtxt(points, skiprows=1)
    points_data *= scale_points

    indices_data, cell_region_data = [], []
    linear_connection_data, linear_connection_regions = [], []

    # elem data
    with open(indices) as elem_file:
        data = elem_file.readlines()
        for elem in data:
            parts = elem.strip().split()
            if parts[0] == 'Tr':
                indices_data.append(list(map(int, parts[1:4])))
                cell_region_data.append(int(float(parts[4])))
            elif parts[0] == 'Ln':
                linear_connection_data.append(list(map(int, parts[1:3])))
                linear_connection_regions.append(int(parts[3]))

    indices_data = np.array(indices_data)
    cell_region = np.array(cell_region_data)
    linear_connection_data = np.array(linear_connection_data)
    linear_connection_regions = np.array(linear_connection_regions)

    fields = Fields(
        cell_region=cell_region,
        longitudinal_fibres=None,
        transverse_fibres=None,
    )

    # Fibres data
    n_cells = indices_data.shape[0]
    if fibres is None:
        _fibres = np.tile([1, 0, 0], (n_cells, 1))
    else:
        with open(fibres, 'r') as f:
            first_value = f.readline().strip().split()[0]

        if first_value == "1":
            _fibres = np.loadtxt(fibres, skiprows=1)
        else:
            _fibres = np.loadtxt(fibres)
        _fibres = _fibres[0:n_cells]

    vectors = Vectors(
        fibres=_fibres,
        linear_connections=linear_connection_data if len(linear_connection_data) > 0 else None,
        linear_connection_regions=linear_connection_regions if len(linear_connection_regions) > 0 else None,
    )

    electric = Electric()
    ablation = Ablation()
    notes = np.asarray([], dtype=object)

    return Case(name, points_data, indices_data, fields, electric, ablation, notes, vectors)


def load_vtk(filename, name=None):
    """
    Load data from a VTK file.

    Args:
        filename (str): path to VTK file to be loaded (including the .vtk
            extension.)
        name (str): name to give this dataset. The default is `None`, in which case
            the filename is used at the name.

    Returns:
        case (Case): an OpenEP Case object that contains the surface, electric and
            ablation data.
    """

    name = name if name is not None else os.path.basename(filename)
    mesh = pyvista.read(filename)

    case = Case(
        name=name,
        points=mesh.points,
        indices=np.array(mesh.faces).reshape(mesh.n_cells, 4)[:, 1:],
        fields=Fields.from_pyvista(mesh),
        electric = Electric(),
        ablation = Ablation(),
        vectors=None,
        notes = np.asarray([], dtype=object),
    )

    return case


def load_igb(igb_filepath):
    """
    Reads an .igb file, returning the data and header information.

    Args:
        igb_filepath (str): Path to the .igb file.

    Returns:
        tuple:
            - numpy.ndarray: 2D array of the file's data.
            - dict: Contents of the header including 't' value (time steps) and other parameters.
    """
    with open(igb_filepath, 'rb') as file:
        header = file.read(1024).decode('utf-8')
        header = header.replace('\r', ' ').replace('\n', ' ').replace('\0', ' ')
        hdr_content = {}

        # Parse the header to dict format
        for part in header.split():
            key, value = part.split(':')
            if key in ['x', 'y', 'z', 't', 'bin', 'num', 'lut', 'comp']:
                hdr_content[key] = int(value)
            elif key in ['facteur','zero','epais'] or key.startswith('org_') or key.startswith('dim_') or key.startswith('inc_'):
                hdr_content[key] = float(value)
            else:
                hdr_content[key] = value

        # Process file data
        words = header.split()
        word = [int(re.split(r"(\d+)", w)[1]) for w in words[:4]]
        nnode = word[0] * word[1] * word[2]
        size = os.path.getsize(igb_filepath) // 4 // nnode

        file.seek(1024)
        data = np.fromfile(file, dtype=np.float32, count=size * nnode)

        num_complete_rows = data.size // nnode
        data = data[:num_complete_rows * nnode].reshape((num_complete_rows, nnode)).transpose()

    return data, hdr_content
